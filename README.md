# DL_project


- The paper addresses fairness in recommender systems by proposing a novel graph-based technique that ensures sensitive features are not exposed during the user modeling process.
- It introduces a method to transform original embeddings of users and items into a filtered embedding space using adversarial learning on a user-centric graph, effectively obfuscating sensitive features.
- Experimental results demonstrate the effectiveness of the proposed model in achieving fair recommendations by mitigating bias related to sensitive user attributes.

